{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8307c010",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abac8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "from IPython.display import clear_output\n",
    "from pythonosc import dispatcher, osc_server\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9fdfdc",
   "metadata": {},
   "source": [
    "# Capturing accelerometer data through OSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5042fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['x', 'y', 'z'])\n",
    "\n",
    "# To keep track for data collection\n",
    "index = 0\n",
    "\n",
    "x = 0\n",
    "y = 0\n",
    "z = 0\n",
    "\n",
    "# Creating a function that will handle and classify accelerometer data\n",
    "def acceleration_vector(address, args):\n",
    "    global data\n",
    "    global index\n",
    "    global x\n",
    "    global y\n",
    "    global z\n",
    "    if address.find('accelerometer/x') != -1:\n",
    "        x = args\n",
    "    elif address.find('accelerometer/y') != -1:\n",
    "        y = args\n",
    "    elif address.find('accelerometer/z') != -1:\n",
    "        z = args\n",
    "        data = data.append({'x': x, 'y': y, 'z': z}, ignore_index=True)\n",
    "        clear_output(wait=True)\n",
    "        print(index)\n",
    "        index = index + 1\n",
    "\n",
    "# Attaching the function to the dispatcher\n",
    "dispatcher = dispatcher.Dispatcher()\n",
    "dispatcher.map(\"/accelerometer/*\", acceleration_vector)\n",
    "\n",
    "# Starting the OSC server\n",
    "server = osc_server.ThreadingOSCUDPServer(('193.157.241.238', 8000), dispatcher)\n",
    "print(\"Serving on {}\".format(server.server_address))\n",
    "server.serve_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d75b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the server\n",
    "server.server_close()\n",
    "\n",
    "# Saving the data to a .csv-file\n",
    "data.to_csv('./data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d26b391",
   "metadata": {},
   "source": [
    "# Using the dataset to train a regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d225e332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score on individual targets [0.99645624 0.98604923]\n"
     ]
    }
   ],
   "source": [
    "#### Read dataset\n",
    "dataset = pd.read_csv('./data/data.csv')\n",
    "\n",
    "# Importing the columns with accelerometer (gravity) data on the three exis\n",
    "rawdata = dataset[['x', 'y', 'z']].to_numpy()\n",
    "inputs = np.empty((0,3))\n",
    "target = np.empty((inputs.shape[0],2))\n",
    "\n",
    "# Iterating through the entries of the dataset and creating associated target values\n",
    "# The index edges for the postures have been found manually by visually inspecting the waveforms\n",
    "for i in range(0,rawdata.shape[0]):\n",
    "    if (2 <= i <= 1025):\n",
    "        inputs = np.append(inputs, rawdata[i,:].reshape(1,-1), axis=0)\n",
    "        target = np.append(target, np.array([[1.,1.]]), axis=0) #looking at phone\n",
    "    elif (1052 <= i <= 1990):\n",
    "        inputs = np.append(inputs, rawdata[i,:].reshape(1,-1), axis=0)\n",
    "        target = np.append(target, np.array([[1.,0.]]), axis=0) #face level to the left\n",
    "    elif (2007 <= i <= 3010):\n",
    "        inputs = np.append(inputs, rawdata[i,:].reshape(1,-1), axis=0)\n",
    "        target = np.append(target, np.array([[0.,1.]]), axis=0) #face level upwards\n",
    "    elif (3050 <= i <= 3937):\n",
    "        inputs = np.append(inputs, rawdata[i,:].reshape(1,-1), axis=0)\n",
    "        target = np.append(target, np.array([[0.,0.]]), axis=0) #face level downwards\n",
    "\n",
    "\n",
    "# Creating train/test split\n",
    "inputs_train, inputs_test, target_train, target_test = sklearn.model_selection.train_test_split(inputs, target, test_size=0.1)\n",
    "\n",
    "# Training the model\n",
    "mlp = sklearn.neural_network.MLPRegressor(hidden_layer_sizes=(8,4), max_iter=20000, activation='logistic')\n",
    "mlp.fit(inputs_train, target_train)\n",
    "target_predict =  mlp.predict(inputs_test)\n",
    "\n",
    "# Print the number of misclassified samples, accuracy and complete report (using scikit learn metric tools) \n",
    "print('r2 score on individual targets',sklearn.metrics.r2_score(target_test, target_predict, multioutput='raw_values'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd096a",
   "metadata": {},
   "source": [
    "# Saving the model to a file, for use in our 'amen_control.py' application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bada8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/mlp_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the classifier model to file\n",
    "joblib_file = \"./data/mlp_model.pkl\"\n",
    "joblib.dump(mlp, joblib_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
